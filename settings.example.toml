# VoiceType Configuration File - Example
# Copy this file to settings.toml and customize as needed

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
# Optional: Specify a custom path for the log file.
# If not specified, uses platform defaults:
#   - Linux: ~/.config/voicetype/voicetype.log
#   - macOS: ~/Library/Application Support/voicetype/voicetype.log
#   - Windows: %APPDATA%/voicetype/voicetype.log

# log_file = "/path/to/custom/voicetype.log"
# log_file = "~/custom/logs/voicetype.log"  # Tilde expansion supported

# =============================================================================
# TELEMETRY CONFIGURATION (OpenTelemetry)
# =============================================================================
# Telemetry is disabled by default. To enable, set enabled = true.
# When enabled, traces are exported to a local file for offline analysis.
# Traces are saved to ~/.config/voicetype/traces.jsonl (or platform equivalent).
#
# View traces with: cat ~/.config/voicetype/traces.jsonl | jq
#
# Optional: You can also export to an OTLP endpoint (e.g., a custom OpenTelemetry
# collector) by setting otlp_endpoint and export_to_file=true for both.

[telemetry]
enabled = false  # Default: disabled (set to true to enable)
service_name = "voicetype"  # Service name shown in traces
export_to_file = true  # Export traces to file (default: true)

# Optional: Export to OTLP endpoint (for custom visualization tools)
# otlp_endpoint = "http://localhost:4317"  # OTLP gRPC endpoint

# Optional: Custom trace file path
# trace_file = "~/my-traces.jsonl"  # Default: ~/.config/voicetype/traces.jsonl

# File rotation settings
rotation_enabled = true  # Enable automatic file rotation (default: true)
rotation_max_size_mb = 10  # Rotate when file reaches this size in MB (default: 10)

# =============================================================================
# STAGE DEFINITIONS
# =============================================================================
# Define named stage instances with their configurations.
# Stages can be referenced by name in pipelines and reused across pipelines.
#
# IMPORTANT: 'stage_class' is a RESERVED field name used to specify which
# stage class to instantiate. Stage implementations cannot use 'stage_class'
# as a configuration parameter name.

[stage_configs.RecordAudio_default]
stage_class = "RecordAudio"
minimum_duration = 0.25  # Minimum audio duration in seconds

# Local transcription with faster-whisper (offline, no API key needed)
[stage_configs.Transcribe_local]
stage_class = "Transcribe"
provider = "local"
# Options below are specific to the "local" provider:
model = "large-v3-turbo"  # Whisper model: "tiny", "base", "small", "medium", "large-v3", "large-v3-turbo"
language = "en"  # Language code: "en", "es", "fr", "de", etc.
device = "cuda"  # Device for inference: "cuda" (GPU) or "cpu"

# Cloud transcription via LiteLLM/OpenAI (requires OPENAI_API_KEY)
[stage_configs.Transcribe_cloud]
stage_class = "Transcribe"
provider = "litellm"
# Options below are specific to the "litellm" provider:
language = "en"  # Language code for transcription
# Note: model and device are not used with litellm provider

[stage_configs.CorrectTypos_default]
stage_class = "CorrectTypos"
case_sensitive = false
whole_word_only = true
corrections = [
    ["machinelearning", "machine learning"],
    ["air quotes", "error codes"],
    ["Python", "python", "case_sensitive=true"],
]

[stage_configs.TypeText_default]
stage_class = "TypeText"

[stage_configs.LLMAgent_jarvis]
stage_class = "LLMAgent"
model = "gpt-4o-mini"  # or "ollama/llama3.2", "claude-3-5-sonnet-20241022", etc.
trigger_keywords = ["jarvis", "hey assistant"]  # REQUIRED: Only invoke LLM if these words are present
                                                # If empty or not configured, LLM will NOT be invoked
# system_prompt is optional - defaults to a Jarvis assistant prompt if not specified
system_prompt = """You are a text transformation assistant.
When you see a trigger word like 'jarvis' or 'hey assistant' in the input:
- Text BEFORE the trigger word is the content to transform
- Text AFTER the trigger word is the instruction for how to transform it
- Apply the instruction and return ONLY the transformed text

Examples:
- Input: "This is my email jarvis make it professional"
  Output: "Dear [Recipient],\n\nThis is my email.\n\nBest regards"
"""
temperature = 0.3
# max_tokens = 500  # Optional: limit response length
# timeout = 30  # Optional: request timeout in seconds
# fallback_on_error = true  # Optional: return original text on error (default: true)

# =============================================================================
# PIPELINE CONFIGURATION
# =============================================================================
# Pipelines define sequences of stages that process voice input.
# Multiple pipelines can be configured with different hotkeys.
#
# Pipelines reference stage instances by name (easier to override/reuse).

# Example 1: Default voice-to-text pipeline
[[pipelines]]
name = "default"
enabled = true
hotkey = "<pause>"  # Pause/Break key
stages = [
    "RecordAudio_default",
    "Transcribe_local",
    "CorrectTypos_default",
    "TypeText_default",
]

# Example 2: Alternative pipeline with cloud transcription (commented out)
# [[pipelines]]
# name = "cloud_transcribe"
# enabled = false
# hotkey = "<f12>"
# stages = [
#     "RecordAudio_default",
#     "Transcribe_cloud",  # Different transcription provider
#     "TypeText_default",
# ]

# Example 3: Voice assistant mode with LLM processing
# [[pipelines]]
# name = "jarvis_mode"
# enabled = false
# hotkey = "<ctrl>+<pause>"
# stages = [
#     "RecordAudio_default",
#     "Transcribe_local",
#     "LLMAgent_jarvis",  # Process with LLM agent
#     "TypeText_default",
# ]

# Example 4: Pipeline with multiple instances of same stage
# To use a stage twice with different configs, create separate named instances
# [stage_configs.CorrectTypos_slang]
# stage_class = "CorrectTypos"
# corrections = [["gonna", "going to"], ["wanna", "want to"]]
#
# [stage_configs.CorrectTypos_technical]
# stage_class = "CorrectTypos"
# corrections = [["machinelearning", "machine learning"]]
#
# [[pipelines]]
# name = "multi_correct"
# enabled = false
# hotkey = "<ctrl>+<pause>"
# stages = [
#     "RecordAudio_default",
#     "Transcribe_local",
#     "CorrectTypos_slang",      # First correction pass
#     "CorrectTypos_technical",  # Second correction pass
#     "TypeText_default",
# ]


# =============================================================================
# CONFIGURATION NOTES
# =============================================================================
#
# Available Stages:
#   - RecordAudio: Records audio while hotkey is held down
#   - Transcribe: Converts audio to text using speech recognition
#   - CorrectTypos: Corrects configured typos and common speech-to-text errors
#   - LLMAgent: Processes text through an LLM agent (local or remote)
#   - TypeText: Types the transcribed text at the current cursor position
#
# Hotkey Format:
#   - Special keys: <pause>, <f1>, <f12>, etc.
#   - Modifiers: <ctrl>+<alt>+p, <shift>+<f1>, etc.
#   - Regular keys: a, b, 1, 2, etc.
#
# Transcription Provider Options:
#   - "local": Uses faster-whisper for local transcription (faster, offline)
#     - model: Whisper model size (tiny, base, small, medium, large-v3, large-v3-turbo)
#     - device: "cuda" for GPU or "cpu" for CPU inference
#     - language: Language code (en, es, fr, de, etc.)
#   - "litellm": Uses cloud-based transcription (requires API key)
#     - language: Language code for transcription
#
# LLM Model Options (for LLMAgent stage):
#   - Local: "ollama/llama3.2", "ollama/mistral", "ollama/phi3" (requires Ollama installed)
#   - Remote: "gpt-4o", "claude-3-5-sonnet-20241022", "gemini/gemini-2.0-flash", etc.
#   - See LiteLLM docs for full list: https://docs.litellm.ai/docs/providers
#
# File Locations (searched in order):
#   1. ./settings.toml (current directory)
#   2. ~/.config/voicetype/settings.toml (user config)
#   3. /etc/voicetype/settings.toml (system-wide)
